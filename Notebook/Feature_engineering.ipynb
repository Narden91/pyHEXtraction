{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abce2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406141a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to folder containing the CSV files\n",
    "year = 2\n",
    "\n",
    "base_feature_path = Path(f\"C:/Users/Emanuele/Desktop/Feat_extr_ANNO{year}/original_features\")\n",
    "\n",
    "path_eng_features = Path(f\"C:/Users/Emanuele/Desktop/Feat_extr_ANNO{year}/eng_features\")\n",
    "\n",
    "if not path_eng_features.exists():\n",
    "    path_eng_features.mkdir(parents=True)\n",
    "    \n",
    "# Load the CSV files in a list\n",
    "csv_files = list(base_feature_path.glob(\"*.csv\"))\n",
    "\n",
    "# Sort the csv fil base by the name Task_1, Task_2, etc.\n",
    "csv_files.sort(key=lambda x: int(x.stem.split('_')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86daed2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep = [\n",
    "    # Mandatory\n",
    "    'Id',\n",
    "\n",
    "    # Dynamic parameters\n",
    "    'mean:pressure', 'std:pressure', 'iqr:pressure',\n",
    "    'mean:tilt(on-surface)', 'std:tilt(on-surface)', 'iqr:tilt(on-surface)',\n",
    "\n",
    "    # Temporal parameters\n",
    "    'writing_duration(on-surface)',\n",
    "    'writing_duration_overall',\n",
    "    'number_of_interruptions',\n",
    "\n",
    "    # Spatial parameters\n",
    "    'writing_width(on-surface)',\n",
    "    'writing_height(on-surface)',\n",
    "    'mean:stroke_width(on-surface)', 'std:stroke_width(on-surface)', 'iqr:stroke_width(on-surface)',\n",
    "    'mean:stroke_height(on-surface)', 'std:stroke_height(on-surface)', 'iqr:stroke_height(on-surface)',\n",
    "\n",
    "    # Kinematic parameters\n",
    "    'mean:velocity:axis-xy(on-surface)',\n",
    "    'std:velocity:axis-xy(on-surface)',\n",
    "    'mean:acceleration:axis-xy(on-surface)',\n",
    "    'std:acceleration:axis-xy(on-surface)',\n",
    "    'mean:jerk:axis-xy(on-surface)',\n",
    "    'mean:stroke_duration(on-surface)',\n",
    "    'mean:stroke_length(on-surface)',\n",
    "    'number_of_changes_in_x_profile',\n",
    "    'number_of_changes_in_y_profile',\n",
    "    'number_of_changes_in_pressure_profile',\n",
    "    \n",
    "    # Personal information\n",
    "    'Gender', 'Age', 'Dominant_Hand', 'Label', 'Task'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48b45b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_in_air_movement_time(df):\n",
    "    \"\"\"\n",
    "    Compute in-air movement time as the difference between overall and on-surface durations.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing at least the columns:\n",
    "        - 'writing_duration_overall'\n",
    "        - 'writing_duration(on-surface)'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Series with the in-air movement time for each row.\n",
    "    \"\"\"\n",
    "    result = df[\"writing_duration_overall\"] - df[\"writing_duration(on-surface)\"]\n",
    "    # Replace negatives (if any) with zero\n",
    "    result[result < 0] = 0\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f09cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_in_air_on_paper_ratio(df):\n",
    "    \"\"\"\n",
    "    Compute ratio between in-air movement time and on-paper movement time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing at least:\n",
    "        - 'writing_duration_overall'\n",
    "        - 'writing_duration(on-surface)'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Series with the in-air/on-paper ratio for each row.\n",
    "    \"\"\"\n",
    "\n",
    "    in_air_time = compute_in_air_movement_time(df)\n",
    "    on_paper_time = df[\"writing_duration(on-surface)\"]\n",
    "    \n",
    "    ratio = np.where(on_paper_time > 0,\n",
    "                     in_air_time / on_paper_time,\n",
    "                     0)\n",
    "    return ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fce2ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_average_normalized_jerk(df):\n",
    "    \"\"\"\n",
    "    Compute Average Normalized Jerk (ANJ) for each row in the DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing at least:\n",
    "        - 'mean:jerk:axis-xy(on-surface)'\n",
    "        - 'mean:stroke_duration(on-surface)'\n",
    "        - 'mean:stroke_length(on-surface)'\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Series with the computed ANJ for each row.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If any required values are zero or negative (e.g. stroke duration or length).\n",
    "    \"\"\"\n",
    "    avg_jerk = df[\"mean:jerk:axis-xy(on-surface)\"]\n",
    "    avg_stroke_duration = df[\"mean:stroke_duration(on-surface)\"]\n",
    "    avg_stroke_length = df[\"mean:stroke_length(on-surface)\"]\n",
    "\n",
    "    # Create a result series, defaulting to zeros\n",
    "    anj = pd.Series(0, index=df.index, dtype=float)\n",
    "\n",
    "    # Define valid rows\n",
    "    valid_mask = (\n",
    "        (avg_stroke_duration > 0) &\n",
    "        (avg_stroke_length > 0) &\n",
    "        (avg_jerk >= 0)\n",
    "    )\n",
    "    \n",
    "    if valid_mask.any():\n",
    "        normalization_factor = (avg_stroke_duration[valid_mask] ** 5) / (avg_stroke_length[valid_mask] ** 2)\n",
    "        anj[valid_mask] = np.sqrt(0.5 * avg_jerk[valid_mask] * normalization_factor)\n",
    "    \n",
    "    return anj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217cca36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_mapping_for_year(year):\n",
    "    \"\"\"\n",
    "    Get the task mapping dictionary based on the year.\n",
    "    \n",
    "    For year 3, we need to rearrange tasks as follows:\n",
    "    - Task_3 becomes Task_1\n",
    "    - Task_4 becomes Task_2  \n",
    "    - Task_5 is skipped (not computed)\n",
    "    - Task_6 becomes Task_3\n",
    "    - Task_7 becomes Task_4\n",
    "    - ... and so on\n",
    "    - Tasks 1, 2, and 5 from original are not computed\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    year : int\n",
    "        The year for which to get the task mapping\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary mapping original task numbers to new task numbers\n",
    "        None values indicate tasks that should be skipped\n",
    "    \"\"\"\n",
    "    if year == 3:\n",
    "        # Create mapping for year 3\n",
    "        task_mapping = {}\n",
    "        \n",
    "        # Tasks 1, 2, and 5 are not computed (skipped)\n",
    "        task_mapping[1] = None\n",
    "        task_mapping[2] = None\n",
    "        task_mapping[5] = None\n",
    "        \n",
    "        # Task 3 becomes Task 1\n",
    "        task_mapping[3] = 1\n",
    "        \n",
    "        # Task 4 becomes Task 2\n",
    "        task_mapping[4] = 2\n",
    "        \n",
    "        # Task 6 onwards: subtract 4 from original task number\n",
    "        # (Task 6 -> 2, Task 7 -> 3, Task 8 -> 4, etc.)\n",
    "        for original_task in range(6, 23):  # Assuming tasks go up to 22\n",
    "            new_task = original_task - 4\n",
    "            task_mapping[original_task] = new_task\n",
    "            \n",
    "        return task_mapping\n",
    "    \n",
    "    else:\n",
    "        # For years 1 and 2, no mapping needed (identity mapping)\n",
    "        return None\n",
    "\n",
    "\n",
    "def rename_csv_file_for_year(csv_file_path, year):\n",
    "    \"\"\"\n",
    "    Rename a CSV file based on the year's task mapping.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_file_path : Path\n",
    "        Path to the CSV file\n",
    "    year : int\n",
    "        The year for which to apply task renaming\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    Path or None\n",
    "        New path for the renamed file, or None if file should be skipped\n",
    "    \"\"\"\n",
    "    task_mapping = get_task_mapping_for_year(year)\n",
    "    \n",
    "    if task_mapping is None:\n",
    "        # No mapping needed for this year\n",
    "        return csv_file_path\n",
    "    \n",
    "    # Extract original task number from filename\n",
    "    filename = csv_file_path.name\n",
    "    if filename.startswith(\"Task_\") and filename.endswith(\".csv\"):\n",
    "        try:\n",
    "            original_task_num = int(filename.split(\"_\")[1].split(\".\")[0])\n",
    "            \n",
    "            # Get new task number from mapping\n",
    "            new_task_num = task_mapping.get(original_task_num)\n",
    "            \n",
    "            if new_task_num is None:\n",
    "                # This task should be skipped\n",
    "                return None\n",
    "            \n",
    "            # Create new filename\n",
    "            new_filename = f\"Task_{new_task_num}.csv\"\n",
    "            new_path = csv_file_path.parent / new_filename\n",
    "            \n",
    "            return new_path\n",
    "            \n",
    "        except (ValueError, IndexError):\n",
    "            # If we can't parse the task number, return original path\n",
    "            return csv_file_path\n",
    "    \n",
    "    # If filename doesn't match expected pattern, return original path\n",
    "    return csv_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d43399",
   "metadata": {},
   "outputs": [],
   "source": [
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    print(f\"Processing {csv_file.name}...\")\n",
    "    \n",
    "    if df.empty:\n",
    "        print(f\"Skipping {csv_file.name} because it is empty.\")\n",
    "        continue\n",
    "\n",
    "    # Check if this file should be processed based on year\n",
    "    new_file_path = rename_csv_file_for_year(csv_file, year)\n",
    "    \n",
    "    if new_file_path is None:\n",
    "        print(f\"Skipping {csv_file.name} - not computed for year {year}\")\n",
    "        continue\n",
    "\n",
    "    df_filtered = df[columns_to_keep].copy()\n",
    "\n",
    "    # Add derived features safely\n",
    "    df_filtered[\"in_air_movement_time\"] = compute_in_air_movement_time(df_filtered)\n",
    "    df_filtered[\"in_air_on_paper_ratio\"] = compute_in_air_on_paper_ratio(df_filtered)\n",
    "    df_filtered[\"average_normalized_jerk\"] = compute_average_normalized_jerk(df_filtered)\n",
    "    \n",
    "    # Update Task column if year 3 remapping is applied\n",
    "    if year == 3 and 'Task' in df_filtered.columns:\n",
    "        # Extract new task number from the new filename\n",
    "        new_task_num = int(new_file_path.stem.split('_')[1])\n",
    "        df_filtered['Task'] = new_task_num\n",
    "        print(f\"Updated Task column from {csv_file.stem} to Task_{new_task_num}\")\n",
    "    \n",
    "    # Move Columns 'Gender', 'Age', 'Dominant_Hand', 'Label', 'Task' to the end\n",
    "    columns_to_move = ['Gender', 'Age', 'Dominant_Hand', 'Label', 'Task']\n",
    "    \n",
    "    for col in columns_to_move:\n",
    "        if col in df_filtered.columns:\n",
    "            # Move the column to the end\n",
    "            df_filtered[col] = df_filtered.pop(col)\n",
    "        else:\n",
    "            print(f\"Column {col} not found in {csv_file.name}, skipping.\")\n",
    "            \n",
    "    # Round numeric columns to 5 decimal places\n",
    "    numeric_cols = df_filtered.select_dtypes(include=[np.number]).columns\n",
    "    df_filtered[numeric_cols] = df_filtered[numeric_cols].round(5)\n",
    "    \n",
    "    # Save the processed DataFrame using the new filename\n",
    "    output_file = path_eng_features / new_file_path.name\n",
    "    df_filtered.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"Saved as {new_file_path.name}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
